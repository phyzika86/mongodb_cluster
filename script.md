## Что я делал в script.py

Этот скрипт на Python используется для настройки и управления кластером MongoDB с шардированием и репликацией. Вот пошаговое описание того, что я делал:

---

### 1. **Подключение к MongoDB**
- Я подключился к конфигурационным серверам и шардам с помощью библиотеки `pymongo`.
- Использовал строки подключения:
  - Для конфигурационных серверов: `mongodb://localhost:27019/?directConnection=true`.
  - Для шардов: `mongodb://localhost:27018/?directConnection=true`.

---

### 2. **Инициализация репликасетов**
- Я создал конфигурации для репликасетов:
  - Для конфигурационных серверов (`configReplSet`).
  - Для каждого шарда (`shard1`, `shard2`, `shard3`).
- Использовал команду `replSetInitiate` для инициализации репликасетов.
- Проверил статус репликасетов с помощью команды `replSetGetStatus`.

---

### 3. **Добавление шардов в кластер**
- Я подключился к маршрутизатору (`mongos`) по адресу `mongodb://localhost:27017/?directConnection=true`.
- Добавил каждый шард в кластер с помощью команды `addShard`.

---

### 4. **Настройка балансировки**
- Проверил статус балансировки кластера.
- Если балансировка была отключена, включил её с помощью команды `update_one` в коллекции `config.settings`.

---

### 5. **Включение шардирования для базы данных**
- Я выбрал базу данных `test_db` и коллекцию `test_collection`.
- Включил шардирование для базы данных с помощью команды `enableSharding`.

---

### 6. **Шардирование коллекции**
- Выбрал ключ шардирования: `{"user_id": "hashed"}`.
- Зашардировал коллекцию `test_collection` с помощью команды `shardCollection`.

---

### 7. **Загрузка данных**
- Я добавил 10 000 документов в коллекцию `test_collection`.
- Каждый документ содержит поля `user_id` и `data`.

---

### 8. **Обработка ошибок**
- На каждом этапе я добавил обработку исключений, чтобы отслеживать возможные ошибки и выводить их в консоль.

---


### 9. **Отслеживание состояния шардирования**
- После загрузки данных я проверил распределение данных по шардам с помощью команды `db.test_collection.getShardDistribution()` через маршрутизатор `mongos`.
- Результат показал, что данные равномерно распределены между шардами:

  ```plaintext
  Shard shard3 at shard3/shard3a:27018,shard3b:27018,shard3c:27018
  {
    data: '392KiB',
    docs: 6497,
    chunks: 2,
    'estimated data per chunk': '196KiB',
    'estimated docs per chunk': 3248
  }

  Shard shard2 at shard2/shard2a:27018,shard2b:27018,shard2c:27018
  {
    data: '401KiB',
    docs: 6647,
    chunks: 2,
    'estimated data per chunk': '200KiB',
    'estimated docs per chunk': 3323
  }

  Shard shard1 at shard1/shard1a:27018,shard1b:27018,shard1c:27018
  {
    data: '398KiB',
    docs: 6597,
    chunks: 2,
    'estimated data per chunk': '199KiB',
    'estimated docs per chunk': 3298
  }

  {
    data: '1.16MiB',
    docs: 19741,
    chunks: 6,
    'Shard shard3': [
      '32.9 % data',
      '32.91 % docs in cluster',
      '61B avg obj size on shard'
    ],
    'Shard shard2': [
      '33.66 % data',
      '33.67 % docs in cluster',
      '61B avg obj size on shard'
    ],
    'Shard shard1': [
      '33.42 % data',
      '33.41 % docs in cluster',
      '61B avg obj size on shard'
    ]
  }

### 10. **Тестирование отказоустойчивости**
Я последовательно "ронял" разные инстансы и наблюдал за поведением кластера.

#### a) **Падение одного из конфигурационных серверов**
- Я остановил контейнер `config1`:
  ```bash
  docker stop config1
- Кластер продолжал работать, так как конфигурационные серверы используют репликацию
- Маршрутизатор (mongos) переключился на оставшиеся конфигурационные серверы (config2 и config3).
- Данные оставались доступными, и запросы обрабатывались без ошибок

#### b) **Падение одного из шардов**
- Я остановил контейнер `shard1a`  (первичная реплика шарда shard1)
- Репликасет шарда shard1 автоматически выбрал новую первичную реплику (shard1b или shard1c)
- Кластер продолжал работать, так как данные были доступны через оставшиеся реплики
- Запросы, которые должны были обрабатываться шардом shard1, перенаправлялись на новую первичную реплику
- Я поднял контейнер shard1a обратно
- Реплика автоматически синхронизировалась с первичной репликой и вернулась в строй

#### b) **Падение маршрутизатора (mongos)**
- Я остановил контейнер router
- Запросы к кластеру перестали обрабатываться, так как маршрутизатор недоступен. Однако данные оставались целыми и сохраненными на шардах.
- Я поднял контейнер router обратно. Маршрутизатор восстановил подключение к конфигурационным серверам и шардам. Кластер снова стал доступен для запросов.
